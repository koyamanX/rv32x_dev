#include "ifetch_unit.h"
#include "csr.h"
#include "priv.h"
#define MEM_WORD        3'b010
#define MEM_HALFWORD    3'b001
#define MEM_BYTE        3'b000

module ifetch_unit {
	proc_name idle();
	/* registering output of mem block is required to infer bram */
	reg cache_data_entry[128];
	reg cache_tag_entry[20];
	reg cache_valid_entry;
	reg cache_tag_accessing[20];	/* physical tag, if no paging, then virtual tag == physical tag */
	reg cache_index_accessing[8];
	proc_name compare_tag(cache_data_entry, cache_tag_entry, cache_valid_entry, cache_tag_accessing, cache_index_accessing);
	reg allocate_addr[32];
	proc_name allocate(allocate_addr); 
	reg ptw_vaddr[32];	/* virtual address used for page_table_walk */
	proc_name page_table_walk(ptw_vaddr);
	proc_name flush_tlb();
	proc_name invalidate_cache();

	mem cache_data[256][128];
	mem cache_valid[256] = {0};
	mem cache_tag[256][20] = {0};

	func_self cache_hit();
	func_self cache_miss();
	wire refill_tag[20];
	wire refill_index[8];
	func_self refill(refill_tag, refill_index);

	mem tlb_data[4][32];
	mem tlb_valid[4] = {0};
	mem tlb_tag[4][20] = {0};
	mem tlb_levels[4][2];
	reg tlb_random_replace_pos[2] = 0;

	wire va[32];
	func_self access_tlb(va);
	wire tlb_hit_data[32];
	wire tlb_hit_levels[2];
	func_self tlb_hit(tlb_hit_data, tlb_hit_levels);
	func_self tlb_miss();

	wire tag[20];
	wire index[8];
	wire blockoffset[2];
	wire byteoffset[2];
	wire sv32;

	integer i_;	/* only used by `generate` construct and re-used in this module */

	.{tag, index, blockoffset, byteoffset} = addr;
	tlb_random_replace_pos++;

	sv32 = (satp_mode && (priv_mode != MACHINE));

	func reset {
		idle();
	}
	proc idle {
		sv32_pte_t wire sv32_pte;

		if(invalidate) {
			invalidate_cache();
		} else if(tlb_flush) {
			flush_tlb();
		} else if(read && sv32) {
			access_tlb(addr);
			if(tlb_hit) {
				sv32_pte = tlb_hit_data;
				if(sv32_pte.v && sv32_pte.x && sv32_pte.a
					&& ((sv32_pte.u && (priv_mode == USER)) || (!sv32_pte.u && priv_mode == SUPERVISOR))) {
					/* map 32 bits virtual address to 32 bits physical address on sv32, not 34 bit physical address for now */
					any {
						tlb_hit_levels == 0:	compare_tag(cache_data[index], cache_tag[index], cache_valid[index], ({sv32_pte.ppn1, sv32_pte.ppn0})[19:0], index);
						tlb_hit_levels == 1:	compare_tag(cache_data[index], cache_tag[index], cache_valid[index], ({sv32_pte.ppn1, addr[21:12]})[19:0], index);
					}
				} else {
					instruction_page_fault();
				}
			} else if(tlb_miss) {
				page_table_walk(addr);
			}
		} else if(read && !sv32) {
			compare_tag(cache_data[index], cache_tag[index], cache_valid[index], tag, index);
		}
	}
	proc flush_tlb {
		generate(i_ = 0; i_ < 4; i_++) {
			tlb_valid[i_] := INVALID;
		}
		tlb_flush_done();
		idle();
	}
	func access_tlb {
		generate(i_ = 0; i_ < 4; i_++) {
			if(tlb_valid[i_] && (tlb_tag[i_] == va[31:12])) {
				tlb_hit(tlb_data[i_], tlb_levels[i_]);
			}
		}
		if(!tlb_hit) {
			tlb_miss();
		}
	}
	proc page_table_walk {
		walk({satp_mode, satp_asid, satp_ppn}, ptw_vaddr);
		if(pte_valid) {
			tlb_data[tlb_random_replace_pos] := pte;
			tlb_tag[tlb_random_replace_pos] := ptw_vaddr[31:12];
			tlb_valid[tlb_random_replace_pos] := VALID;
			tlb_levels[tlb_random_replace_pos] := pte_levels;
			idle();
		} else if(page_fault) {
			instruction_page_fault();
			idle();
		} else if(access_fault) {
			instruction_access_fault();
		}
	}
	proc compare_tag {
		/* checking (cache_index_accessing == index) is required, to support cancellation of read operation in this stage 
			if not above equation holds, then read is cancelled implicitly by changing `addr` during `read` (in the case of
			branch, jump and trap), so restart from idle();
		*/
		if(cache_valid_entry && (cache_tag_entry == cache_tag_accessing) && (cache_index_accessing == index)) {
			cache_hit();
			idle();
		} else if(cache_index_accessing != index) {
			idle();
		} else {
			cache_miss();
			/* use physical tag and page_offset(untranslated part of addr(lower 12 bits))
				to form address for allocate cache block 
				again, if sv32 is not enabled, physical tag maps to virtual tag */
			allocate({cache_tag_accessing, addr[11:0]});
		}
	}
	func cache_hit {
		wire cache_block[128];
		wire cache_word[32];

		cache_block = cache_data_entry;
		any {
			blockoffset == 2'b00: cache_word = cache_block[31:0];
			blockoffset == 2'b01: cache_word = cache_block[63:32];
			blockoffset == 2'b10: cache_word = cache_block[95:64];
			blockoffset == 2'b11: cache_word = cache_block[127:96];
		}
		if(read) {
			inst = cache_word;
			ready();
		}
	}
	proc allocate {
		wire allocate_tag[20];
		wire allocate_index[8];
		wire allocate_blockoffset[2];
		wire allocate_byteoffset[2];
		.{allocate_tag, allocate_index, allocate_blockoffset, allocate_byteoffset} = allocate_addr;

		/* mem_read with physical address */
		mem_read({allocate_tag, allocate_index, 4'b0000});
		if(mem_ready) {
			refill(allocate_tag, allocate_index);
			idle();
		}
	}
	func refill {
		cache_data[refill_index] := mem_rdata;
		cache_tag[refill_index] := refill_tag;
		cache_valid[refill_index] := VALID;
	}
	proc invalidate_cache seq {
		reg invalidate_cnt[9] = 0;
		wire invalidate_index[8];

		/* no dirty cache entry, just invaldate all entry */
		for(invalidate_cnt := 0; invalidate_cnt < 256; invalidate_cnt++) {
			invalidate_index = invalidate_cnt[7:0];
			cache_valid[invalidate_index] := INVALID;
		}
		{
			invalidate_done();
			idle();
		}
	}
}
